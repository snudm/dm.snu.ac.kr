<strong>[이재원 석박통합과정, 박서영 석사과정, 선지민 석사과정 SKT AI Fellowship 2기 최우수팀 선정]</strong>
<br>
<br>
서울대 공과대학(학장 차국헌)은 산업공학과 데이터마이닝 연구실(지도교수: 조성준 교수)의 이재원 석박통합과정, 박서영 석사과정, 선지민 석사과정이 AI 연구에 큰 성과를 내고 SK텔레콤 주관 SKT AI Fellowship 2기 최우수팀에 선정됐다.<br>
SKT AI Fellowship은 SK텔레콤이 전국 대학(원)생들을 대상으로 AI, 5G 등 ICT 주요 분야 실무 경험 및 연구 기회를 제공하는 프로그램으로 2019년부터 시행해 올해 2기가 운영됐다.
지난 5월 2회에 걸친 심사 과정을 통해 총 여섯 팀이 SKT AI Fellowship 2기로 선발되었고 이들은 이후 6개월간 AI, Big Data, Mobility, Security 등 ICT 주요 분야의 주제에 대한 과제를 수행했다.
최우수팀으로 선정된 세 연구원의 주제는 ‘한국어 요약 모델 연구개발 및 요약 데이터셋 구축(Korean Summarization Model & Dataset)’이었으며, SK텔레콤의 멘토(전희원 리서치엔지니어, SK텔레콤 AI랭귀지테크랩스)와 함께 연구를 진행했다.<br>

연구원들은 한국어 딥러닝 기술인 KoBERT를 활용한 모델로 ‘요약(summarization)’이라는 문제를 풀고, 모델 학습에 필요한 한국어 요약 데이터셋을 구축했다.
2018년 구글에서 발표한 획기적인 BERT 모델은 자연어처리의 지형을 바꾸었다. 2019년 SK텔레콤에서 한국어에 특화된 BERT 모델인 KoBERT를 개발하여 오픈소스로 공개했고, 이는 다양한 한국어 자연어처리 과제의 발전에 기여했다.
‘요약’은 법률 문서나 논문과 같은 긴 문서부터 상품 리뷰, 고객 상담로그와 같은 비교적 짧은 문서까지 모두 적용할 수 있기에 활용 방안이 무궁무진하다. 한국어 요약은 영어 요약에 비해 상대적으로 연구가 덜 진행되어온 자연어처리 분야 중 하나로 발전 가능성이 매우 높다.<br>

최종 결과물은 SK텔레콤의 검토를 거쳐 오픈소스로 공개될 예정이다. 연구원들은 “이번 연구를 통해 향후 한국어 요약, 나아가 한국어 자연어처리의 연구발전에 기여하고자 한다”고 포부를 밝혔다.<br><br>
세 연구원의 최종 연구 결과물은 다음과 같다.<br>
1) 하나의 문서에 대해 사람처럼 새롭게 요약을 생성해내는 단일문서 생성요약모델(Single-document Abstractive Model) 3개를 한국어에 맞게 변형하여 구현(Pointer-Generator Network, PreSumm, BART). 3개 모델의 학습에 필요한 데이터셋을 구축하기 위해 동일 주제를 다루되 다른 언론사에서 제작한 뉴스 기사의 추출요약을 조합하는 방식을 고안 후 활용<br>
2) 여러 개의 문서에서 가장 중요한 문장을 가져오는 다중문서 추출요약모델(Multi-document Extractive Model) 구현(TextRank+MMR). 이 모델의 학습에 필요한 다중문서 요약 데이터셋을 구축하기 위해 다양한 언론사의 뉴스 기사를 주제별로 묶는 방식을 고안<br>

연구팀은 최우수팀 자격으로 연구 성과를 SK텔레콤 전체 구성원 대상으로 발표하는 시간도 가질 예정이다.<br>

연구원들은 “펠로우십 기간 동안 전폭적인 지지를 해준 전희원 멘토와 SK텔레콤 역량문화그룹 담당자, 아낌없이 조언해주시고 격려해주신 조성준 지도교수님 및 데이터마이닝 연구실 선후배님들께 진심으로 감사드린다”라고 전했다.